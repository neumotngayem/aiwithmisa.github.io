---
layout: post
title: "[Th·ª±c H√†nh] B√†i 6 H·ªìi quy tuy·∫øn t√≠nh - Linear Regression"
subtitle: "Lo·∫°t b√†i h·ªçc thu·ªôc series AML"
date: 2020-12-13
author: "KyoHB"
header-img: "img/post-bg-aml.jpg"
tags: [AML]
---

Ch√∫ng ta s·∫Ω c√πng th·ª±c h√†nh tri·ªÉn khai hu·∫•n luy·ªán (training) m·ªôt Linear Regression model cho m·ªôt b√†i to√°n d·ª± ƒëo√°n gi√° nh√† nh√© !


<span style='color: #f44336'>* C√°c b√†i th·ª±c h√†nh ƒë·ªÅu s·ª≠ d·ª•ng Python 3.</span>


# **Import t·∫≠p d·ªØ li·ªáu**

T·∫≠p d·ªØ li·ªáu (dataset) ƒë∆∞·ª£c s·ª≠ d·ª•ng trong b√†i th·ª±c h√†nh n√†y l√† t·∫≠p d·ªØ li·ªáu (dataset) ·ªü link sau:



[Download T·∫≠p d·ªØ li·ªáu](https://www.kaggle.com/quantbruce/real-estate-price-prediction)


```python
import pandas as pd
```


```python
df = pd.read_csv('Real estate.csv', index_col=0)
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1 transaction date</th>
      <th>X2 house age</th>
      <th>X3 distance to the nearest MRT station</th>
      <th>X4 number of convenience stores</th>
      <th>X5 latitude</th>
      <th>X6 longitude</th>
      <th>Y house price of unit area</th>
    </tr>
    <tr>
      <th>No</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2012.917</td>
      <td>32.0</td>
      <td>84.87882</td>
      <td>10</td>
      <td>24.98298</td>
      <td>121.54024</td>
      <td>37.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2012.917</td>
      <td>19.5</td>
      <td>306.59470</td>
      <td>9</td>
      <td>24.98034</td>
      <td>121.53951</td>
      <td>42.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2013.583</td>
      <td>13.3</td>
      <td>561.98450</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>47.3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2013.500</td>
      <td>13.3</td>
      <td>561.98450</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>54.8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2012.833</td>
      <td>5.0</td>
      <td>390.56840</td>
      <td>5</td>
      <td>24.97937</td>
      <td>121.54245</td>
      <td>43.1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>410</th>
      <td>2013.000</td>
      <td>13.7</td>
      <td>4082.01500</td>
      <td>0</td>
      <td>24.94155</td>
      <td>121.50381</td>
      <td>15.4</td>
    </tr>
    <tr>
      <th>411</th>
      <td>2012.667</td>
      <td>5.6</td>
      <td>90.45606</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>50.0</td>
    </tr>
    <tr>
      <th>412</th>
      <td>2013.250</td>
      <td>18.8</td>
      <td>390.96960</td>
      <td>7</td>
      <td>24.97923</td>
      <td>121.53986</td>
      <td>40.6</td>
    </tr>
    <tr>
      <th>413</th>
      <td>2013.000</td>
      <td>8.1</td>
      <td>104.81010</td>
      <td>5</td>
      <td>24.96674</td>
      <td>121.54067</td>
      <td>52.5</td>
    </tr>
    <tr>
      <th>414</th>
      <td>2013.500</td>
      <td>6.5</td>
      <td>90.45606</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>63.9</td>
    </tr>
  </tbody>
</table>
<p>414 rows √ó 7 columns</p>
</div>



T·∫≠p d·ªØ li·ªáu (dataset) n√†y bao g·ªìm 414 c√° th·ªÉ (instance) bao g·ªìm c√≥ 6 bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable) v√† m·ªôt bi·∫øn ph·ª• thu·ªôc (dependent variable) ƒë√≥ l√† gi√° m·ªôt $m^{2}$ nh√†.

# **Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu**

M·ªôt trong nh·ªØng c√¥ng vi·ªác quan tr·ªçng khi hu·∫•n luy·ªán (training) Linear Regression model ƒë√≥ l√† ch√∫ng ta c·∫ßn xem s·ª± t∆∞∆°ng quan (correlation) gi·ªØa c√°c bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable) v√† bi·∫øn ph·ª• thu·ªôc (dependent variable), c≈©ng nh∆∞ng gi·ªØa c√°c bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable).


```python
import seaborn as sns

import matplotlib.pyplot as plt
```


```python
corr_matrix = df.corr()

sns.heatmap(corr_matrix, annot=True)

plt.show()
```


![png]({{ site.baseurl }}/img/in-post/aml/AI_with_Misa_Linear_Regression_9_0.png)


Qua ma tr·∫≠n t∆∞∆°ng quan (correlation matrix) tr√™n ch√∫ng ta c√≥ th·ªÉ th·∫•y bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable) X1 transaction date, g·∫ßn nh∆∞ kh√¥ng c√≥ t√°c ƒë·ªông g√¨ ƒë·∫øn gi√° nh√†, m·ª©c ƒë·ªô t∆∞∆°ng quan g·∫ßn nh∆∞ b·∫±ng 0 (0.087), ch√∫ng ta s·∫Ω lo·∫°i b·ªè bi·∫øn kh√¥ng ph·ª• thu·ªôc n√†y. Nh√¨n v√†o ma tr·∫≠n t∆∞∆°ng quan (correlation matrix) n√†y ch√∫ng ta c≈©ng th·∫•y nh·ªØng v·∫•n ƒë·ªÅ r·∫•t logic: gi√° nh√† s·∫Ω tƒÉng n·∫øu tu·ªïi th·ªç ng√¥i nh√† th·∫•p (X2 house age c√≥ m·ª©c ƒë·ªô t∆∞∆°ng quan v·ªõi gi√° nh√† l√† -0.21), nh√† c√†ng xa tr·∫°m t√†u ƒëi·ªán th√¨ gi√° nh√† c≈©ng c√†ng gi·∫£m (X3 distance to the nearest MRT station c√≥ m·ª©c ƒë·ªô t∆∞∆°ng quan v·ªõi gi√° nh√† l√† -0.67), s·ªë l∆∞·ª£ng c·ª≠a h√†ng ti·ªán l·ª£i c√†ng nhi·ªÅu th√¨ gi√° nh√† c√†ng tƒÉng (X4 number of convenience stores c√≥ m·ª©c ƒë·ªô t∆∞∆°ng quan v·ªõi gi√° nh√† l√† 0.57). Tuy nhi√™n bi·∫øn kh√¥ng ph·ª• thu·ªôc X3 distance to the nearest MRT station c≈©ng l·∫°i c√≥ m·ª©c ƒë·ªô t∆∞∆°ng quan cao v·ªõi c√°c bi·∫øn kh√°c, t·∫°o ra nguy c∆° c·ªông tuy·∫øn (collinearity) cho Linear Regression model, do ƒë√≥ ch√∫ng ta c≈©ng c·∫ßn ph·∫£i lo·∫°i b·ªè bi·∫øn n√†y.


```python
df_new = df.drop(df.columns[[0,2]], axis=1)

df_new
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X2 house age</th>
      <th>X4 number of convenience stores</th>
      <th>X5 latitude</th>
      <th>X6 longitude</th>
      <th>Y house price of unit area</th>
    </tr>
    <tr>
      <th>No</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>32.0</td>
      <td>10</td>
      <td>24.98298</td>
      <td>121.54024</td>
      <td>37.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>19.5</td>
      <td>9</td>
      <td>24.98034</td>
      <td>121.53951</td>
      <td>42.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>47.3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>54.8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.0</td>
      <td>5</td>
      <td>24.97937</td>
      <td>121.54245</td>
      <td>43.1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>410</th>
      <td>13.7</td>
      <td>0</td>
      <td>24.94155</td>
      <td>121.50381</td>
      <td>15.4</td>
    </tr>
    <tr>
      <th>411</th>
      <td>5.6</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>50.0</td>
    </tr>
    <tr>
      <th>412</th>
      <td>18.8</td>
      <td>7</td>
      <td>24.97923</td>
      <td>121.53986</td>
      <td>40.6</td>
    </tr>
    <tr>
      <th>413</th>
      <td>8.1</td>
      <td>5</td>
      <td>24.96674</td>
      <td>121.54067</td>
      <td>52.5</td>
    </tr>
    <tr>
      <th>414</th>
      <td>6.5</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>63.9</td>
    </tr>
  </tbody>
</table>
<p>414 rows √ó 5 columns</p>
</div>



C√πng ki·ªÉm tra xem c√≥ d·ªØ li·ªáu tr·ªëng (missing value) ·ªü t·∫≠p d·ªØ li·ªáu n√†y (dataset) n√†y kh√¥ng nh√©.


```python
import missingno as msno
```


```python
x = df_new.iloc[:,0:4]

x
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X2 house age</th>
      <th>X4 number of convenience stores</th>
      <th>X5 latitude</th>
      <th>X6 longitude</th>
    </tr>
    <tr>
      <th>No</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>32.0</td>
      <td>10</td>
      <td>24.98298</td>
      <td>121.54024</td>
    </tr>
    <tr>
      <th>2</th>
      <td>19.5</td>
      <td>9</td>
      <td>24.98034</td>
      <td>121.53951</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
    </tr>
    <tr>
      <th>4</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.0</td>
      <td>5</td>
      <td>24.97937</td>
      <td>121.54245</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>410</th>
      <td>13.7</td>
      <td>0</td>
      <td>24.94155</td>
      <td>121.50381</td>
    </tr>
    <tr>
      <th>411</th>
      <td>5.6</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
    </tr>
    <tr>
      <th>412</th>
      <td>18.8</td>
      <td>7</td>
      <td>24.97923</td>
      <td>121.53986</td>
    </tr>
    <tr>
      <th>413</th>
      <td>8.1</td>
      <td>5</td>
      <td>24.96674</td>
      <td>121.54067</td>
    </tr>
    <tr>
      <th>414</th>
      <td>6.5</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
    </tr>
  </tbody>
</table>
<p>414 rows √ó 4 columns</p>
</div>




```python
msno.bar(x)
```



![png]({{ site.baseurl }}/img/in-post/aml/AI_with_Misa_Linear_Regression_15_1.png)


Kh√¥ng c√≥ gi√° tr·ªã tr·ªëng (missing value) trong t·∫≠p d·ªØ li·ªáu (dataset) c·ªßa ch√∫ng ta.

B∆∞·ªõc ti·∫øp theo ch√∫ng ta s·∫Ω ki·ªÉm tra xem c√≥ gi√° tr·ªã ngo·∫°i bi√™n (outlier) trong t·∫≠p d·ªØ li·ªáu (dataset) kh√¥ng nh√©. Gi√° tr·ªã ngo·∫°i bi√™n (outlier) l√† m·ªôt gi√° tr·ªã l·ªõn h∆°n ho·∫∑c nh·ªè h∆°n h·∫≥n so v·ªõi c√°c c√° th·ªÉ (instance) trong t·∫≠p d·ªØ li·ªáu (dataset), c√°c gi√° tr·ªã n√†y v√¥ h√¨nh chung l√† cho sai l·ªách trong qu√° tr√¨nh hu·∫•n luy·ªán (training) ML model. V√≠ d·ª• minh h·ªça cho outlier trong m·ªôt t·∫≠p d·ªØ li·ªáu (H√£y nh√¨n v√†o s·ªë li·ªáu c·ªßa c√°c Player kh√°c v√† Player 3):



![image.png](data:image/png;base64,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)



ƒê·ªÉ ph√°t hi·ªán ƒë∆∞·ª£c outlier trong t·∫≠p d·ªØ li·ªáu (dataset), ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng bi·ªÉu ƒë·ªì h·ªôp (box plot) nh√© ! ƒê·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ box plot h√£y xem video d∆∞·ªõi ƒë√¢y:



[Bi·ªÉu ƒë·ªì h·ªôp Box-plot](https://www.youtube.com/watch?v=eW7I2a0Bgs0)


```python
fig = sns.boxplot(data=df_new)

fig.set_xticks(range(5))

fig.set_xticklabels(['X2', 'X4', 'X5', 'X6', 'Y'])
```




    [Text(0, 0, 'X2'),
     Text(0, 0, 'X4'),
     Text(0, 0, 'X5'),
     Text(0, 0, 'X6'),
     Text(0, 0, 'Y')]




![png]({{ site.baseurl }}/img/in-post/aml/AI_with_Misa_Linear_Regression_19_1.png)


Qua bi·ªÉu ƒë·ªì h·ªôp (box plot) c·ªßa 4 bi·∫øn kh√¥ng ph·ª• thu·ªôc (dependent variable), ch√∫ng ta th·∫•y kh√¥ng c√≥ xu·∫•t hi·ªán outlier ·ªü ngo√†i kho·∫£ng min v√† max. Tuy nhi√™n ·ªü bi·∫øn ph·ª• thu·ªôc (dependent variable) ch√∫ng ta l·∫°i th·∫•y c√≥ xu·∫•t hi·ªán outlier, ƒë√¢y l√† c√°c gi√° tr·ªã l·ªõn h∆°n h·∫≥n max c·ªßa Y, ch√∫ng ta c·∫ßn lo·∫°i b·ªè c√°c c√° th·ªÉ (instance) n√†y.


```python
# T√≠nh Q1 v√† Q3 c·ªßa t·ª´ng bi·∫øn trong t·∫≠p d·ªØ li·ªáu (dataset)

q1 = df_new.quantile(0.25)

q3 = df_new.quantile(0.75)

# T√≠nh IQR

iqr = q3 - q1

iqr
```




    X2 house age                       19.125000
    X4 number of convenience stores     5.000000
    X5 latitude                         0.014455
    X6 longitude                        0.015220
    Y house price of unit area         18.900000
    dtype: float64




```python
# Lo·∫°i b·ªè c√°c c√° th·ªÉ c√≥ gi√° tr·ªã l·ªõn h∆°n max v√† nh·ªè h∆°n min c·ªßa t·ª´ng bi·∫øn
df_without_outlier = df_new[~((df_new < (q1 - 1.5 * iqr)) |(df_new > (q3 + 1.5 * iqr))).any(axis=1)]

df_without_outlier
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X2 house age</th>
      <th>X4 number of convenience stores</th>
      <th>X5 latitude</th>
      <th>X6 longitude</th>
      <th>Y house price of unit area</th>
    </tr>
    <tr>
      <th>No</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>32.0</td>
      <td>10</td>
      <td>24.98298</td>
      <td>121.54024</td>
      <td>37.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>19.5</td>
      <td>9</td>
      <td>24.98034</td>
      <td>121.53951</td>
      <td>42.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>47.3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>54.8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.0</td>
      <td>5</td>
      <td>24.97937</td>
      <td>121.54245</td>
      <td>43.1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>409</th>
      <td>18.5</td>
      <td>3</td>
      <td>24.96330</td>
      <td>121.51243</td>
      <td>28.1</td>
    </tr>
    <tr>
      <th>411</th>
      <td>5.6</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>50.0</td>
    </tr>
    <tr>
      <th>412</th>
      <td>18.8</td>
      <td>7</td>
      <td>24.97923</td>
      <td>121.53986</td>
      <td>40.6</td>
    </tr>
    <tr>
      <th>413</th>
      <td>8.1</td>
      <td>5</td>
      <td>24.96674</td>
      <td>121.54067</td>
      <td>52.5</td>
    </tr>
    <tr>
      <th>414</th>
      <td>6.5</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>63.9</td>
    </tr>
  </tbody>
</table>
<p>371 rows √ó 5 columns</p>
</div>



Ki·ªÉm tra l·∫°i bi·ªÉu ƒë·ªì h·ªôp (box plot) sau khi ƒë√£ lo·∫°i tr·ª´ c√°c gi√° tr·ªã ngo·∫°i bi√™n (outlier).


```python
fig = sns.boxplot(data=df_without_outlier)

fig.set_xticks(range(5))

fig.set_xticklabels(['X2', 'X4', 'X5', 'X6', 'Y'])
```




    [Text(0, 0, 'X2'),
     Text(0, 0, 'X4'),
     Text(0, 0, 'X5'),
     Text(0, 0, 'X6'),
     Text(0, 0, 'Y')]




![png]({{ site.baseurl }}/img/in-post/aml/AI_with_Misa_Linear_Regression_24_1.png)


Do c√°c gi√° tr·ªã ·ªü bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable) kh√¥ng qu√° ch√™nh l·ªách nhi·ªÅu (h√†ng ch·ª•c v√† ƒë∆°n v·ªã) n√™n ch√∫ng ta kh√¥ng c·∫ßn ph·∫£i chu·∫©n h√≥a (normalize). T·∫≠p d·ªØ li·ªáu (dataset) c·ªßa ch√∫ng ta ƒë√£ c√≥ th·ªÉ ti·∫øn h√†nh hu·∫•n luy·ªán (training)

# **Ph√¢n chia t·∫≠p d·ªØ li·ªáu**

·ªû b∆∞·ªõc n√†y ch√∫ng ta s·∫Ω chia d·ªØ li·ªáu ra l√†m 2 t·∫≠p nh·ªè h∆°n, t·∫≠p hu·∫•n luy·ªán (training set) v√† t·∫≠p x√°c nh·∫≠n (validation set) v·ªõi t·ª∑ l·ªá 80% v√† 20%.

<span style='color: #f44336'>* random_state nh·∫±m ƒë·∫£m b·∫£o vi·ªác ph√¢n chia d·ªØ li·ªáu l√† nh∆∞ nhau trong m·ªçi l·∫ßn ch·∫°y.</span>

```python
y = df_without_outlier['Y house price of unit area']

y
```




    No
    1      37.9
    2      42.2
    3      47.3
    4      54.8
    5      43.1
           ... 
    409    28.1
    411    50.0
    412    40.6
    413    52.5
    414    63.9
    Name: Y house price of unit area, Length: 371, dtype: float64




```python
from sklearn.model_selection import train_test_split
```


```python
x_without_outlier = df_without_outlier.iloc[:,0:4]

X_train, X_valid, Y_train, Y_valid = train_test_split(x_without_outlier, y, test_size = 0.2, random_state = 101)
```

# **Hu·∫•n luy·ªán regression model**


```python
from sklearn.linear_model import LinearRegression
```

Kh·ªüi t·∫°o Linear Regression model


```python
regressor = LinearRegression()
```

Fit Linear Regression model v·ª´a kh·ªüi t·∫°o v·ªõi t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán (training set)


```python
regressor.fit(X_train, Y_train)
```




    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)



Xem c√°c model parameter c·ªßa model ch√∫ng ta v·ª´a hu·∫•n huy·ªán xong nh√©


```python
regressor.coef_
```




    array([-3.03451439e-01,  1.44280883e+00,  4.58836606e+02,  2.63959238e+02])



Ch√∫ng ta c√≥ 4 tr·ªçng s·ªë (weight) t∆∞∆°ng ·ª©ng c·ªßa 4 bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable): X2 house age, X4 number of convenience stores, X5 latitude,	X6 longitude


```python
regressor.intercept_
```




    -43499.661316731115



C√ì th·ªÉ vi·∫øt l·∫°i h√†m s·ªë tuy·∫øn t√≠nh (linear function) c·ªßa model c·ªßa ch√∫ng ta s·∫Ω nh∆∞ sau:



$y = -0.303X_{2} + 1.443X_{4} + 458.8X_{5} - 263.9X_{6} - 43499.66$

# **Ki·ªÉm tra Linear Regression ƒë√£ hu·∫•n luy·ªán** #


```python
pred = regressor.predict(X_valid)
```


```python
from sklearn.metrics import mean_squared_error

import math
```

ƒê·∫ßu ti√™n ch√∫ng ta s·∫Ω t√≠nh Root Mean Square Error (RMSE)


```python
math.sqrt(mean_squared_error(Y_valid, pred))
```




    7.898845664720699



Sai s·ªë ·ªü ƒë√¢y l√† kho·∫£ng 8\\$, t·ª©c l√† v·ªõi m·ªói gi√° nh√† d·ª± ƒëo√°n ch√™nh l·ªách so v·ªõi th·ª±c t·∫ø (nhi·ªÅu h∆°n ho·∫∑c √≠t h∆°n) 8\\$.

M·ªôt con ch·ªâ kh√°c ch√∫ng ta c√≥ th·ªÉ tham kh·∫£o ƒë√≥ l√† $R^{2}$, ƒë√¢y l√† ch·ªâ s·ªë mi√™u t·∫£ t·ª∑ l·ªá ph∆∞∆°ng sai (variance) c·ªßa bi·∫øn ph·ª• thu·ªôc (dependent variable) ƒë∆∞·ª£c gi·∫£i th√≠ch (explain) b·ªüi c√°c bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable). Ch·ªâ s·ªë $R^{2}$ n·∫±m trong thang t·ª´ 0-1, c√†ng g·∫ßn 1 th√¨ model c√†ng ch√≠nh x√°c.


```python
from sklearn.metrics import r2_score
```


```python
r2_score(Y_valid, pred)
```




    0.49820177247193564



C√≥ th·ªÉ th·∫•y model c·ªßa ch√∫ng ta kh√¥ng th·∫≠t s·ª± t·ªët, $R^{2}$ ch·ªâ ·ªü m·ª©c 0.49, c√≥ th·ªÉ l√† do ph√¢n ph·ªëi (distribution) c·ªßa t·∫≠p d·ªØ li·ªáu l√† phi tuy·∫øn t√≠nh (non linear).

# **Chuy·ªÉn ƒë·ªïi sang Polynomial Regression**

Qua vi·ªác ki·ªÉm tra Linear Regression model ƒë√£ hu·∫•n luy·ªán, ch√∫ng ta c√≥ th·ªÉ th·∫•y k·∫øt qu·∫£ kh√¥ng ƒë∆∞·ª£c nh∆∞ k·ª≥ v·ªçng, do ƒë√≥ ƒë·ªÉ tƒÉng hi·ªáu nƒÉng c·ªßa ML model, ch√∫ng ta c√πng bi·∫øn ƒë·ªïi c√°c bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable) sang c√°c ƒë·∫∑c tr∆∞ng (feature) Polynomial ƒë·ªÉ xem c√≥ gi√∫p c·∫£i thi·ªán ƒë∆∞·ª£c hi·ªáu nƒÉng kh√¥ng.


```python
from sklearn.preprocessing import PolynomialFeatures
```

Ch√∫ng ta s·∫Ω chuy·ªÉn ƒë·ªïi sang c√°c bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable) sang c√°c ƒë·∫∑c tr∆∞ng (feature) Polynomial b·∫≠c (degree) 3. 



V·ªõi vi·ªác bi·∫øn ƒë·ªïi sang b·∫≠c (degree) 3, Polynomial Regression model ch√∫ng ta s·∫Ω c√≥ c√°c bi·∫øn kh√¥ng ph·ª• thu·ªôc (independent variable):







*   Bias: 1

*   B·∫≠c(Degree) 1: $X_{2}, X_{4}, X_{5}, X_{6}$

*   B·∫≠c(Degree) 2: $X_{2}^{2}, X_{4}^{2}, X_{5}^{2}, X_{6}^{2}$

*   B·∫≠c(Degree) 3: $X_{2}^{3}, X_{4}^{3}, X_{5}^{3}, X_{6}^{3}$

*   T∆∞∆°ng t√°c (Interaction): $X_{2} \times X_{4}, X_{2} \times X_{5}, X_{4} \times X_{6},...$


```python
poly_feature  = PolynomialFeatures(degree= 3)

x_poly = poly_feature.fit_transform(x_without_outlier)
```


```python
import numpy as np
```


```python
x_poly = np.asarray(x_poly)

x_poly
```




    array([[1.00000000e+00, 3.20000000e+01, 1.00000000e+01, ...,
            7.58592545e+04, 3.69049329e+05, 1.79539606e+06],
           [1.00000000e+00, 1.95000000e+01, 9.00000000e+00, ...,
            7.58427674e+04, 3.69005898e+05, 1.79536371e+06],
           [1.00000000e+00, 1.33000000e+01, 5.00000000e+00, ...,
            7.58887548e+04, 3.69137799e+05, 1.79555871e+06],
           ...,
           [1.00000000e+00, 1.88000000e+01, 7.00000000e+00, ...,
            7.58362458e+04, 3.68991626e+05, 1.79537922e+06],
           [1.00000000e+00, 8.10000000e+00, 5.00000000e+00, ...,
            7.57609311e+04, 3.68812040e+05, 1.79541512e+06],
           [1.00000000e+00, 6.50000000e+00, 9.00000000e+00, ...,
            7.58085170e+04, 3.68938913e+05, 1.79552281e+06]])



C≈©ng nh∆∞ ·ªü tr√™n ch√∫ng ta c≈©ng s·∫Ω chia ra hai t·∫≠p d·ªØ li·ªáu nh·ªè h∆°n, m·ªôt t·∫≠p ƒë·ªÉ hu·∫•n luy·ªán (training set), m·ªôt t·∫≠p ƒë·ªÉ x√°c nh·∫≠n (validation set)


```python
X_train_poly, X_valid_poly, Y_train_poly, Y_valid_poly = train_test_split(x_poly, y, test_size = 0.2, random_state = 101)
```

L∆∞u √Ω l√† ch√∫ng ta v·∫´n s·ª≠ d·ª•ng Linear Regression, nh∆∞ng ch·ªâ kh√°c l√† ch√∫ng ta s·∫Ω fit n√≥ v·ªõi c√°c ƒë·∫∑c tr∆∞ng (feature) Polynomial v·ª´a t·∫°o ra ·ªü tr√™n


```python
poly_regressor = LinearRegression()
```


```python
poly_regressor.fit(X_train_poly, Y_train_poly)
```




    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)



Ki·ªÉm tra hi·ªáu nƒÉng c·ªßa Polynomial Regression v·ª´a t·∫°o ra nh√©


```python
pred = poly_regressor.predict(X_valid_poly)
```


```python
math.sqrt(mean_squared_error(Y_valid_poly, pred))
```




    6.1589550610291335




```python
r2_score(Y_valid_poly, pred)
```




    0.6949184550706298



C√≥ th·ªÉ th·∫•y ML model c·ªßa ch√∫ng ta ƒë√£ ƒë∆∞·ª£c c·∫£i thi·ªán l√™n r·∫•t nhi·ªÅu, RMSE gi·∫£m xu·ªëng c√≤n 6\\$, trong kh√≥ ƒëi $R_{2}$ tƒÉng l√™n 0.695 !  

C√°c b·∫°n c√≥ th·ªÉ thay ƒë·ªïi c√°c th√¥ng s·ªë trong qu√° tr√¨nh hu·∫•n luy·ªán (training) nh∆∞ b·∫≠c c·ªßa c√°c ƒë·∫∑c tr∆∞ng (feature) Polynomial, kh√¥ng lo·∫°i b·ªè bi·∫øn X3 distance to the nearest MRT station,... Sau ƒë√≥ comment ·ªü d∆∞·ªõi b√†i vi·∫øt n√†y ƒë·ªÉ xem s·ª± kh√°c bi·ªát nh√© üòÅ

