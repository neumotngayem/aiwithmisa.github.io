---
layout: post
title: "[Lý Thuyết] Bài 7 Hồi quy Logistic - Logistic Regression"
subtitle: "Loạt bài học thuộc series AML"
date: 2020-12-14
author: "KyoHB"
header-img: "img/post-bg-aml.jpg"
tags: [AML]
---

Qua bài 4 và 5 chúng ta đã tìm hiểu và thực hành về Supervised ML model đầu tiên - Linear Regression model, nhằm giải quyết các bài toán regression. Hôm nay chúng ta sẽ tìm hiểu về 
Logistic Regression model, đây là một linear model giúp giải quyết các bài toán classification ví dụ như phân loại ốm hay khỏe mạnh, gian lận hay không gian lận,..

Trong bài toán phân loại, chúng ta cần Logistic Regression tạo ra một đường phân định (decision boundary) giúp phân loại các nhóm (class) của dữ liệu như hình mô tả dưới đây:

![]({{ site.baseurl }}/img/in-post/aml/logistic-regression.png)*Source: cs.tufts.edu*
{:.image-caption}

Hàm số tuyến tính (linear function) chúng ta mong muốn sẽ là:

$score = w_{0} + w_{1}x$
{:.formula}

Sự khác biệt của hàm số tuyến tính (linear function) trên với hàm số của Linear Regression nằm ở bên vế trái, giá trị của biến không phụ thuộc (dependent variable) y giờ được thay bằng score, vậy score này là gì ? Score này được kỳ vọng sẽ giúp chúng phân loại cá thể (instance) vào các nhóm (class). Ở đây chúng ta sẽ để ý đến 2 thứ:

1. Dấu của score, dấu của score sẽ chúng ta biết nhóm (class) của cá thể (instance). Giả sử chúng ta có 2 nhóm (class) là -1 và 1. Nếu dấu của score là âm thì nó sẽ thuộc về nhóm (class) -1 và dấu là dương thì nó sẽ thuộc về nhóm (class) 1.
2. Độ lớn của score, chúng ta có thể thấy những cá thế (instance)càng xa đường phân định (decision boundary) càng chắc chắc điểm đó thuộc về nhóm (class) đó. Các cá thế (instance) ở càng gần đường phân định, tương ứng với score bằng 0 sẽ có thể thuộc về 1 trong 2 nhóm (class), và những điểm này là những điểm khá mơ hồ (confuse), ở hình trên chúng ta thấy có một vài cá thể (instance) thuộc nhóm (class) xanh nhưng thuộc khu vực của nhóm (class) đỏ và ngược lại. 


![]({{ site.baseurl }}/img/in-post/aml/score-logistic.png)*Source: coursera.org*
{:.image-caption}

Tuy nhiên score không thể làm chúng ta hài lòng, điều chúng ta muốn là xác xuất (probability) của cá thể (instance) này thuộc về nhóm (class) là bao nhiêu phần trăm. Do đó, score sẽ được đưa vào logistic function, hay tên gọi khác đó là softmax của score. Softmax trong trường hợp chỉ có 2 nhóm (class) - binary classification còn được gọi là Sigmoid. Vậy hàm số Sigmoid (Sigmoid function) có tác dụng gì ?

![]({{ site.baseurl }}/img/in-post/aml/sigmoid.png)*Source: coursera.org*
{:.image-caption}

Sigmoid sẽ chuyển đổi score chúng ta có được ở trên, thành xác suất (probability) của cá thể đó thuộc nhóm (class) 1, ký hiệu là $P(y = 1\| x_{i}, w)$. Trong đó $x_{i}$, $w$ chính là biểu thị của hàm số tuyến tính $w_{0} + w_{1}x$, ký hiệu trên được hiểu là xác xuất của cá thể (instance) thuộc nhóm (class) 1 với  hàm số tuyến tính (linear function) đã cho (given). Thông thường chúng ta sẽ đặt 0.5 là ngưỡng (Threshold) như đã đề cập ở bài số 3, nếu xác xuất (probability) lớn hơn 0.5 chúng ta sẽ quy định cá thể (instance) thuộc nhóm class (1), nếu nhỏ hơn sẽ thuộc nhóm (class) 0. Để hình dùng cụ thể hơn về cách Sigmoid chuyển đổi Score thành xác suất (probability) chúng ta hãy xem công thức của hàm số Sigmoid, cũng như đồ thị của nó.

$P(y = 1\| x_{i}, w) = \frac{1}{1+e^{-score}}$
{:.formula}

![]({{ site.baseurl }}/img/in-post/aml/sigmoid-plot.png)*Source: coursera.org*
{:.image-caption}

Có thể thấy đặc chưng của Sigmoid function đó là bão hòa (saturate) ở 0 và 1 khi các giá trị của score càng lớn hoặc càng nhỏ, giúp chuyển đổi score ra xác xuất (probability) mà chúng ta mong muốn.

Tiếp tục đến với hàm mất mát (loss function) của Logistic Regression, đối với các bài toán phân loại (classification), hàm mất mát (loss function) thường được sử dụng đó là cross entropy loss. 

$cross\,\,entropy\,\,loss = -\frac{1}{n} \sum_{1}^{n}y_{i}\, log \left ( p(x_{i}) \right ) + (1 - y_{i})\, log \left ( 1 -p(x_{i}) \right )$
{:.formula}

Trong đó n là số cá thể (instance) của tập dữ liệu

Để hiểu cách hoạt động của cross entropy loss, chúng ta hãy cùng xét trường hợp sau. Chúng ta có cá thể (instance) thuộc nhóm (class) 1, tương ứng với $y_{i}$ bằng 1, tuy nhiên Logistic regression model của chúng ta lại dự đoán $p(x_{i})$ bằng 0, khi đó $log (p(x_{i}))$ tương ứng với $log (0)$ và có giá trị âm vô cùng, loss của chúng ta sẽ rất lớn, chứng tỏ model đang dự đoán sai. Điều tương tự sẽ xảy ra trong trường hợp cá thể thuộc nhóm (class) 0, nhưng lại được dự đoán với xác suất là 1. 

